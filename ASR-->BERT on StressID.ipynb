{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XslW5ZaPBPHX"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "SADpath=\"/content/drive/MyDrive/SAD_v1.csv\"\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)  # For 3 stress levels\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2201f29",
        "outputId": "a64defde-32fd-438f-cce6-5fea3f1d922c"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eceaf545"
      },
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['sentence'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"Datasets tokenized successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e8203e0"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "predictions = trainer.predict(tokenized_eval_dataset)\n",
        "\n",
        "\n",
        "eval_labels = tokenized_eval_dataset['labels']\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(eval_labels, predictions.predictions.argmax(axis=-1))\n",
        "\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "\n",
        "print(\"Classification Report: \")\n",
        "print(classification_report(eval_labels, predictions.predictions.argmax(axis=-1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XslW5ZaPBPH"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "SADpath=\"/content/drive/MyDrive/SAD_v1.csv\"\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68de430b"
      },
      "source": [
        "import os\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/fine_tuned_bert_model\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "trainer.save_model(save_path)\n",
        "\n",
        "tokenizer.save_pretrained(save_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fe7d339"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/bert_merged_model\"\n",
        "\n",
        "\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(save_path)\n",
        "\n",
        "\n",
        "loaded_tokenizer = BertTokenizer.from_pretrained(save_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f820267"
      },
      "source": [
        "def tokenize_function(examples):\n",
        "    return loaded_tokenizer(examples['sentence'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "cfb9fc37",
        "outputId": "a1a639e9-d2d4-4b37-be4c-90f3f59109fc"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=loaded_model,\n",
        "    args=training_args,\n",
        "    eval_dataset=tokenized_eval_dataset\n",
        ")\n",
        "\n",
        "\n",
        "predictions = trainer.predict(tokenized_eval_dataset)\n",
        "\n",
        "\n",
        "preds = predictions.predictions.argmax(axis=-1);\n",
        "\n",
        "\n",
        "eval_labels = tokenized_eval_dataset['labels']\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(eval_labels, preds)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "print(\"Classification Report: \")\n",
        "print(classification_report(eval_labels, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9445255474452555\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.23      0.31        75\n",
            "           1       0.96      0.99      0.97      1295\n",
            "\n",
            "    accuracy                           0.94      1370\n",
            "   macro avg       0.72      0.61      0.64      1370\n",
            "weighted avg       0.93      0.94      0.93      1370\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "758a57f3",
        "outputId": "6751fed4-810f-4eec-a0c4-ab034981abd7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'text': eval_dataset['sentence'],\n",
        "    'true_label': eval_dataset['labels'],\n",
        "    'predicted_label': preds\n",
        "})\n",
        "\n",
        "\n",
        "print(comparison_df.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  true_label  \\\n",
            "0  i have a really busy schedule this weekend and...           1   \n",
            "1  our president is sick and he needs to be remov...           1   \n",
            "2  I'm feeling so lost in life is my biggest prob...           1   \n",
            "3                      we are short staffed at work.           1   \n",
            "4  Late, mind you, because someone messed up my s...           0   \n",
            "5  i got insanely sick somewhere around wednesday...           1   \n",
            "6  been trying for days to book doc apt and still...           1   \n",
            "7                                  Looking for a Job           1   \n",
            "8                              sick kids and animals           1   \n",
            "9            Got into another fight with my brother.           1   \n",
            "\n",
            "   predicted_label  \n",
            "0                1  \n",
            "1                1  \n",
            "2                1  \n",
            "3                1  \n",
            "4                1  \n",
            "5                1  \n",
            "6                1  \n",
            "7                1  \n",
            "8                1  \n",
            "9                1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5540fc3c"
      },
      "source": [
        "pip install soundfile librosa pydub transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load bert model"
      ],
      "metadata": {
        "id": "N6wHkj-qfHjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/bert_merged_model\"\n",
        "\n",
        "\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(save_path);\n",
        "\n",
        "\n",
        "loaded_tokenizer = BertTokenizer.from_pretrained(save_path);\n",
        "\n"
      ],
      "metadata": {
        "id": "_tIIknIQfJIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43f5a363"
      },
      "source": [
        "## Load ASR Model ( from facebook)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "077a398a"
      },
      "source": [
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "\n",
        "\n",
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "asr_processor = Wav2Vec2Processor.from_pretrained(model_name);\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(model_name);\n",
        "\n",
        "print(f\"ASR model '{model_name}' and processor loaded successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One item prediction"
      ],
      "metadata": {
        "id": "bqxNJCo3hCjb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f921d23"
      },
      "source": [
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "\n",
        "def convert_mp3_to_wav_and_load(mp3_path, target_sample_rate=16000):\n",
        "\n",
        "    audio = AudioSegment.from_mp3(mp3_path);\n",
        "\n",
        "\n",
        "    wav_data = io.BytesIO();\n",
        "    audio.export(wav_data, format=\"wav\");\n",
        "    wav_data.seek(0);\n",
        "\n",
        "\n",
        "    y, sr = librosa.load(wav_data, sr=target_sample_rate);\n",
        "    return y, sr;\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42e671e0"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def transcribe_audio(mp3_path):\n",
        "    \"\"\"\n",
        "    Transcribes an MP3 audio file to text using the loaded ASR model.\n",
        "    \"\"\"\n",
        "\n",
        "    waveform, sample_rate = convert_mp3_to_wav_and_load(mp3_path, target_sample_rate=16000);\n",
        "\n",
        "\n",
        "    input_values = asr_processor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\").input_values;\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = asr_model(input_values).logits;\n",
        "\n",
        "    predicted_ids = torch.argmax(logits, dim=-1);\n",
        "    transcription = asr_processor.batch_decode(predicted_ids)[0];\n",
        "    return transcription;\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f9bba2e",
        "outputId": "e6b8c780-a2a6-49a5-e95c-f9b01e206d96"
      },
      "source": [
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import torch\n",
        "\n",
        "def predict_stress(text):\n",
        "    \"\"\"\n",
        "    Predicts the stress label (0 or 1) for a given text using the loaded BERT model,\n",
        "    applying label inversion as previously identified.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = loaded_tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128);\n",
        "\n",
        "\n",
        "    device = loaded_model.device;\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()};\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(**inputs);\n",
        "\n",
        "    logits = outputs.logits;\n",
        "    predicted_class_id = torch.argmax(logits, dim=-1).item();\n",
        "\n",
        "    return predicted_class_id;\n",
        "\n",
        "def process_audio_for_stress(mp3_file_path):\n",
        "    \"\"\"\n",
        "    Orchestrates the ASR and BERT prediction steps for an MP3 file.\n",
        "    Accepts an MP3 file path, transcribes it, and then outputs the predicted stress level.\n",
        "    \"\"\"\n",
        "\n",
        "    transcribed_text = transcribe_audio(mp3_file_path);\n",
        "    print(f\"Transcribed Text: {transcribed_text}\");\n",
        "\n",
        "\n",
        "    predicted_stress_label = predict_stress(transcribed_text);\n",
        "\n",
        "    return transcribed_text, predicted_stress_label;\n",
        "\n",
        "\n",
        "sample_mp3_path = \"/content/sample_audio.mp3\";\n",
        "\n",
        "\n",
        "duration_ms = 3000;\n",
        "sample_rate = 16000;\n",
        "silence_audio = AudioSegment.silent(duration=duration_ms, frame_rate=sample_rate);\n",
        "silence_audio.export(sample_mp3_path, format=\"mp3\");\n",
        "\n",
        "print(f\"Dummy MP3 created at: {sample_mp3_path}\");\n",
        "\n",
        "\n",
        "transcribed_text, predicted_stress_label = process_audio_for_stress(sample_mp3_path);\n",
        "\n",
        "print(f\"Final Transcribed Text: '{transcribed_text}'\");\n",
        "print(f\"Final Predicted Stress Label: {predicted_stress_label} (0: No Stress, 1: Stress)\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy MP3 created at: /content/sample_audio.mp3\n",
            "Transcribed Text: \n",
            "Final Transcribed Text: ''\n",
            "Final Predicted Stress Label: 0 (0: No Stress, 1: Stress)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8608be39",
        "outputId": "f1ed1bd5-360f-4575-bce4-33b108f5e6f7"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "base_mp3_path = \"/content/drive/MyDrive/WuHaoAllenCentad/stress_id_wav_filtered\";\n",
        "\n",
        "\n",
        "mp3_files = [\n",
        "    \"2ea4_Counting1.mp3\",\n",
        "    \"45lx_Speaking.mp3\"\n",
        "];\n",
        "\n",
        "print(\"Processing audio files for transcription and stress identification...\");\n",
        "print(\"-------------------------------------------------------------------\");\n",
        "\n",
        "results = [];\n",
        "\n",
        "for file_name in mp3_files:\n",
        "    mp3_full_path = os.path.join(base_mp3_path, file_name);\n",
        "    print(f\"\\nProcessing file: {file_name}\");\n",
        "\n",
        "    if not os.path.exists(mp3_full_path):\n",
        "        print(f\"ERROR: File not found at {mp3_full_path}. Please ensure the MP3 file is uploaded to your Google Drive.\");\n",
        "        transcribed_text = \"N/A (File Not Found)\";\n",
        "        predicted_stress_label = \"N/A\";\n",
        "    else:\n",
        "        try:\n",
        "            transcribed_text, predicted_stress_label = process_audio_for_stress(mp3_full_path);\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR processing {file_name}: {e}\");\n",
        "            transcribed_text = \"N/A (Processing Error)\";\n",
        "            predicted_stress_label = \"N/A\";\n",
        "\n",
        "    results.append({\n",
        "        \"filename\": file_name,\n",
        "        \"transcription\": transcribed_text,\n",
        "        \"stress_label\": predicted_stress_label\n",
        "    });\n",
        "\n",
        "print(\"-------------------------------------------------------------------\");\n",
        "print(\"Processing complete. Here are the results:\");\n",
        "for res in results:\n",
        "    print(f\"\\nFile: {res['filename']}\");\n",
        "    print(f\"  Transcribed Text: '{res['transcription']}'\");\n",
        "    print(f\"  Predicted Stress Label: {res['stress_label']} (0: No Stress, 1: Stress)\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing audio files for transcription and stress identification...\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "Processing file: 2ea4_Counting1.mp3\n",
            "Transcribed Text: ONE HUNDRED NINETY SEVEN NINETY FOUR NINETY ONE EIGHTY EIGHT A EIGHTY FIVE EIGHTY TWO SEVENTY NINE SEVENTY SIX SEVENTY THREE SEVEN SIXTY SEVEN SIXTY FOUR SIXTY ONE FIFTY EIGHT FIFTY FIVE FIFTY TWO FORTY NINE FORTY SIX FORTY THREE FOUR THIRTY SEVEN THIRTEIGHT FOUR\n",
            "\n",
            "Processing file: 45lx_Speaking.mp3\n",
            "Transcribed Text: OND O CA SO I'M BELY A SHET WITER PEOPLE AND EA I CAN SOD B BROES AND ERI AN GLE SHOCKINGT PEOPLE BUT HESNT LIOY AND  WHAT AS I I CAN WRITE WELL I CAN SOLD MOHE MONEY A TROS AND YE SANT TOLK TO LONGINGE AND I AM GOING TO PLY IN ANIN EXPERIMENTS AN MY WORK SO IF IT WOST  WODWO TENTERS THER LIS AD NOT VEY GOOD TO IMAGINE PEOPLE AND  SON TAAN SO AN  SLOY I KNOW THAT YOU GOT TRO FINKS BETTER YOU WORKIN DO BETTER SHALLY GO EE HAYHIN  NOTE A WATY NOISE ERI IS NETE\n",
            "-------------------------------------------------------------------\n",
            "Processing complete. Here are the results:\n",
            "\n",
            "File: 2ea4_Counting1.mp3\n",
            "  Transcribed Text: 'ONE HUNDRED NINETY SEVEN NINETY FOUR NINETY ONE EIGHTY EIGHT A EIGHTY FIVE EIGHTY TWO SEVENTY NINE SEVENTY SIX SEVENTY THREE SEVEN SIXTY SEVEN SIXTY FOUR SIXTY ONE FIFTY EIGHT FIFTY FIVE FIFTY TWO FORTY NINE FORTY SIX FORTY THREE FOUR THIRTY SEVEN THIRTEIGHT FOUR'\n",
            "  Predicted Stress Label: 0 (0: No Stress, 1: Stress)\n",
            "\n",
            "File: 45lx_Speaking.mp3\n",
            "  Transcribed Text: 'OND O CA SO I'M BELY A SHET WITER PEOPLE AND EA I CAN SOD B BROES AND ERI AN GLE SHOCKINGT PEOPLE BUT HESNT LIOY AND  WHAT AS I I CAN WRITE WELL I CAN SOLD MOHE MONEY A TROS AND YE SANT TOLK TO LONGINGE AND I AM GOING TO PLY IN ANIN EXPERIMENTS AN MY WORK SO IF IT WOST  WODWO TENTERS THER LIS AD NOT VEY GOOD TO IMAGINE PEOPLE AND  SON TAAN SO AN  SLOY I KNOW THAT YOU GOT TRO FINKS BETTER YOU WORKIN DO BETTER SHALLY GO EE HAYHIN  NOTE A WATY NOISE ERI IS NETE'\n",
            "  Predicted Stress Label: 0 (0: No Stress, 1: Stress)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing BERT Model on complex sentences"
      ],
      "metadata": {
        "id": "_wqCAoi4hGeF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c1e27ce",
        "outputId": "c60651e3-1eff-4227-c322-a31038c6b0c0"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_text_stress(text):\n",
        "    \"\"\"\n",
        "    Predicts whether a given text indicates stress using the fine-tuned BERT model.\n",
        "    Args:\n",
        "        text (str): The input text to analyze.\n",
        "    Returns:\n",
        "        str: The predicted label (\"Stressed\" or \"Not Stressed\").\n",
        "        float: The confidence score of the prediction.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval();\n",
        "\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128);\n",
        "\n",
        "\n",
        "    device = model.device;\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()};\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs);\n",
        "\n",
        "\n",
        "    logits = outputs.logits;\n",
        "    probs = F.softmax(logits, dim=-1);\n",
        "\n",
        "\n",
        "    pred_class = torch.argmax(probs, dim=-1).item();\n",
        "    confidence = probs[0][pred_class].item();\n",
        "\n",
        "\n",
        "    label_map = {0: \"Not Stressed\", 1: \"Stressed\"};\n",
        "\n",
        "    return label_map[pred_class], confidence;\n",
        "\n",
        "\n",
        "print(\"Text-only Stress Identification Pipeline Ready.\\n\");\n",
        "\n",
        "test_sentences = [\n",
        "    \"I am feeling really overwhelmed with all the work I have to do.\",\n",
        "    \"The weather is beautiful today, and I feel great.\",\n",
        "    \"I'm so anxious about the upcoming deadline, I can't sleep.\",\n",
        "    \"I just had a nice lunch with my friends.\",\n",
        "    \"I can't sleep because its exams season. I can't fail biology again else I'm done for\",\n",
        "    \"I have an exam tomorrow but its chill. Probably not that hard since its just an aptitude test\",\n",
        "    \"I am feeling anxious. Cooking is such a relaxing activity, because its just fun to do! Weather\",\n",
        "    \"Testing testing testing\"\n",
        "];\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    label, conf = predict_text_stress(sentence);\n",
        "    print(f\"Text: \\\"{sentence}\\\"\");\n",
        "    print(f\"Prediction: {label} (Confidence: {conf:.2%})\\n\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text-only Stress Identification Pipeline Ready.\n",
            "\n",
            "Text: \"I am feeling really overwhelmed with all the work I have to do.\"\n",
            "Prediction: Stressed (Confidence: 99.98%)\n",
            "\n",
            "Text: \"The weather is beautiful today, and I feel great.\"\n",
            "Prediction: Not Stressed (Confidence: 99.70%)\n",
            "\n",
            "Text: \"I'm so anxious about the upcoming deadline, I can't sleep.\"\n",
            "Prediction: Stressed (Confidence: 99.98%)\n",
            "\n",
            "Text: \"I just had a nice lunch with my friends.\"\n",
            "Prediction: Stressed (Confidence: 93.98%)\n",
            "\n",
            "Text: \"I can't sleep because its exams season. I can't fail biology again else I'm done for\"\n",
            "Prediction: Stressed (Confidence: 99.90%)\n",
            "\n",
            "Text: \"I have an exam tomorrow but its chill. Probably not that hard since its just an aptitude test\"\n",
            "Prediction: Stressed (Confidence: 99.98%)\n",
            "\n",
            "Text: \"I am feeling anxious. Cooking is such a relaxing activity, because its just fun to do! Weather\"\n",
            "Prediction: Stressed (Confidence: 81.13%)\n",
            "\n",
            "Text: \"Testing testing testing\"\n",
            "Prediction: Stressed (Confidence: 98.11%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b44610d6"
      },
      "source": [
        "## Training BERT Model : Load and merge SAD and dreaddit into one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1135ad94"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "sad_path = '/content/drive/MyDrive/SAD_v1.csv';\n",
        "dreaddit_train_path = '/content/dreaddit-train.csv';\n",
        "dreaddit_test_path = '/content/dreaddit-test.csv';\n",
        "\n",
        "\n",
        "df_sad = pd.read_csv(sad_path);\n",
        "print(f\"SAD dataset loaded. Shape: {df_sad.shape}\");\n",
        "\n",
        "df_dreaddit_train = pd.read_csv(dreaddit_train_path);\n",
        "print(f\"Dreaddit train loaded. Shape: {df_dreaddit_train.shape}\");\n",
        "\n",
        "\n",
        "if os.path.exists(dreaddit_test_path):\n",
        "    df_dreaddit_test = pd.read_csv(dreaddit_test_path);\n",
        "    print(f\"Dreaddit test loaded.  {df_dreaddit_test.shape}\");\n",
        "else:\n",
        "    print(f\" {dreaddit_test_path} not found??\");\n",
        "    df_dreaddit_test = pd.DataFrame(columns=['text', 'label']);\n",
        "\n",
        "\n",
        "df_sad = df_sad.rename(columns={'sentence': 'text', 'is_stressor': 'labels'});\n",
        "\n",
        "df_sad = df_sad[['text', 'labels']];\n",
        "\n",
        "\n",
        "if 'label' in df_dreaddit_train.columns:\n",
        "    df_dreaddit_train = df_dreaddit_train.rename(columns={'label': 'labels'});\n",
        "df_dreaddit_train = df_dreaddit_train[['text', 'labels']];\n",
        "\n",
        "\n",
        "if 'label' in df_dreaddit_test.columns:\n",
        "    df_dreaddit_test = df_dreaddit_test.rename(columns={'label': 'labels'});\n",
        "if not df_dreaddit_test.empty:\n",
        "    df_dreaddit_test = df_dreaddit_test[['text', 'labels']];\n",
        "\n",
        "\n",
        "dfs_to_merge = [df_sad, df_dreaddit_train];\n",
        "if not df_dreaddit_test.empty:\n",
        "    dfs_to_merge.append(df_dreaddit_test);\n",
        "\n",
        "merged_df = pd.concat(dfs_to_merge, ignore_index=True);\n",
        "\n",
        "\n",
        "print(f\"Merged DataFrame shape: {merged_df.shape}\");\n",
        "print(merged_df.head());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d9ae9b3",
        "outputId": "2ba3f5b7-7cd2-4772-a755-678f21095266"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "merged_df['labels'] = merged_df['labels'].astype(int);\n",
        "\n",
        "\n",
        "train_df, eval_df = train_test_split(merged_df, test_size=0.2, random_state=42, stratify=merged_df['labels']);\n",
        "\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True));\n",
        "eval_dataset = Dataset.from_pandas(eval_df.reset_index(drop=True));\n",
        "\n",
        "print(\"Data preprocessing complete.\");\n",
        "print(f\"Train dataset size: {len(train_dataset)}\");\n",
        "print(f\"Eval dataset size: {len(eval_dataset)}\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing complete.\n",
            "Train dataset size: 7750\n",
            "Eval dataset size: 1938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e0cc4c75fe8942ce959c5b31e272c959",
            "fdc37a0b19d5423fb81d8668b0b3179e",
            "7f88666d6fde41d7bc9e918b36909f1f",
            "a8c5054e0de8462c9692840dcb356fa4",
            "65e387cc937741c9b28c855ab2e7fa66",
            "49d5bf6daab348d996a4fb15fd6eeee5",
            "2cc4f73fb43b428ea63972273c740978",
            "0ff56177ceb1433aaf1184c85a05c001",
            "9b0646f303204b52a2078e2cf87f6bb0",
            "f5e8aa64d767406384fa76148d4a537d",
            "c612d17e05b1477cb0d625ec6a36eb22",
            "a94ae46417ce44eba364e7c9605ddab2",
            "062ef14c041f4e58860fb169ea822f62",
            "36b751521f4045aaa259d5a8870a018d",
            "991020bb0e5d4735b92f57f77e488adf",
            "0caa2527fc4f402ab7ba8fc3b67f3677",
            "9787a77e363b4742a8df37624a88826c",
            "5f77ad00bc9e40f882a3d43362c52a9d",
            "50fe01f62db74f6c90ace99a323ef092",
            "22051d29ceae42beabe56bc930598291",
            "720d67abf72c4ea9ad972c1f924cefb1",
            "cfd0a53df87a4759be87ba781f161d05"
          ]
        },
        "id": "410a976c",
        "outputId": "15ad0be5-f870-4398-991a-d2a625f3b5d2"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased');\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True);\n",
        "\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True);\n",
        "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True);\n",
        "\n",
        "print(\"Tokenization complete.\");\n",
        "print(\"Keys in tokenized dataset:\", tokenized_train_dataset[0].keys());"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7750 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0cc4c75fe8942ce959c5b31e272c959"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1938 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a94ae46417ce44eba364e7c9605ddab2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete.\n",
            "Keys in tokenized dataset: dict_keys(['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ad79301"
      },
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2);\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ");\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset\n",
        ");\n",
        "\n",
        "print(\"Starting training...\");\n",
        "trainer.train();\n",
        "print(\"Training complete.\");\n",
        "\n",
        "\n",
        "predictions = trainer.predict(tokenized_eval_dataset);\n",
        "preds = predictions.predictions.argmax(axis=-1);\n",
        "true_labels = tokenized_eval_dataset['labels'];\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(true_labels, preds);\n",
        "print(f\"Accuracy: {accuracy}\");\n",
        "print(\"Classification Report:\");\n",
        "print(classification_report(true_labels, preds));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85270101"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6e95e30",
        "outputId": "2eeaefdc-869b-4ba6-d000-ab1094848884"
      },
      "source": [
        "import os\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "destination_path = '/content/drive/MyDrive/bert_merged_model';\n",
        "\n",
        "\n",
        "model.save_pretrained(destination_path);\n",
        "tokenizer.save_pretrained(destination_path);\n",
        "\n",
        "print(f\"Model and tokenizer successfully saved to '{destination_path}'.\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer successfully loaded from '/content/drive/MyDrive/fine_tuned_bert_model' and saved to '/content/drive/MyDrive/bert_merged_model'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9045f850"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f6b7105",
        "outputId": "912a6baa-be9d-4746-e5cc-64ec36f6d6eb"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    report_to='none'\n",
        ");\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    eval_dataset=tokenized_eval_dataset\n",
        ");\n",
        "\n",
        "\n",
        "predictions = trainer.predict(tokenized_eval_dataset);\n",
        "preds = predictions.predictions.argmax(axis=-1);\n",
        "true_labels = tokenized_eval_dataset['labels'];\n",
        "accuracy = accuracy_score(true_labels, preds);\n",
        "\n",
        "print(f\"Accuracy on merged dataaset: {accuracy}\");\n",
        "print(classification_report(true_labels, preds));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on merged dataset: 0.913828689370485\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.72      0.75       345\n",
            "           1       0.94      0.96      0.95      1593\n",
            "\n",
            "    accuracy                           0.91      1938\n",
            "   macro avg       0.86      0.84      0.85      1938\n",
            "weighted avg       0.91      0.91      0.91      1938\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "988bc15a",
        "outputId": "36c204af-aa3e-4c0b-a769-8ba7cf03368c"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "def predict_stress(text):\n",
        "    \"\"\"\n",
        "    Predicts the stress probability (class 1) for a given text using the loaded BERT model.\n",
        "    \"\"\"\n",
        "\n",
        "    loaded_model.eval();\n",
        "\n",
        "\n",
        "    inputs = loaded_tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128);\n",
        "\n",
        "\n",
        "    device = loaded_model.device;\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()};\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(**inputs);\n",
        "\n",
        "    logits = outputs.logits;\n",
        "\n",
        "    probs = F.softmax(logits, dim=-1);\n",
        "\n",
        "\n",
        "    stressed_probability = probs[0][1].item();\n",
        "    return stressed_probability;\n",
        "\n",
        "def process_audio_for_stress(mp3_file_path):\n",
        "    \"\"\"\n",
        "    Orchestrates the ASR and BERT prediction steps for an MP3 file.\n",
        "    Accepts an MP3 file path, transcribes it, and then outputs the predicted stress probability.\n",
        "    \"\"\"\n",
        "\n",
        "    transcribed_text = transcribe_audio(mp3_file_path);\n",
        "    print(f\"Transcribed Text: {transcribed_text}\");\n",
        "\n",
        "\n",
        "    predicted_stress_probability = predict_stress(transcribed_text);\n",
        "\n",
        "    return transcribed_text, predicted_stress_probability;\n",
        "\n",
        "\n",
        "if 'sample_mp3_path' not in locals() or not os.path.exists(sample_mp3_path):\n",
        "    sample_mp3_path = \"/content/sample_audio.mp3\";\n",
        "    duration_ms = 3000;\n",
        "    sample_rate = 16000;\n",
        "    silence_audio = AudioSegment.silent(duration=duration_ms, frame_rate=sample_rate);\n",
        "    silence_audio.export(sample_mp3_path, format=\"mp3\");\n",
        "    print(f\"Dummy MP3 created at: {sample_mp3_path}\");\n",
        "\n",
        "print(\"Updated 'predict_stress' and 'process_audio_for_stress' functions.\");\n",
        "\n",
        "\n",
        "transcribed_text, predicted_stress_probability = process_audio_for_stress(sample_mp3_path);\n",
        "\n",
        "print(f\"Final Transcribed Text: '{transcribed_text}'\");\n",
        "print(f\"Final Predicted Stress Probability (class 1): {predicted_stress_probability:.4f}\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated 'predict_stress' and 'process_audio_for_stress' functions.\n",
            "Transcribed Text: \n",
            "Final Transcribed Text: ''\n",
            "Final Predicted Stress Probability (class 1): 0.0847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be5b9f35"
      },
      "source": [
        "## Evaluation on stressidtest2.csv + Get probabilities for all audio files in both eval and train for ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edd36128",
        "outputId": "e945930c-ca64-4b34-8a30-937fee060cd6"
      },
      "source": [
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "\n",
        "def load_audio_and_resample(file_path, target_sample_rate=16000):\n",
        "    \"\"\"\n",
        "    Loads an audio file (MP3, WAV, etc.), resamples it to the target sample rate,\n",
        "    and returns it as a NumPy array.\n",
        "    \"\"\"\n",
        "\n",
        "    audio = AudioSegment.from_file(file_path);\n",
        "\n",
        "\n",
        "    wav_data = io.BytesIO();\n",
        "    audio.export(wav_data, format=\"wav\");\n",
        "    wav_data.seek(0);\n",
        "\n",
        "\n",
        "    y, sr = librosa.load(wav_data, sr=target_sample_rate);\n",
        "    return y, sr;\n",
        "\n",
        "print(\"Function 'load_audio_and_resample' defined for general audio processing.\");\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    \"\"\"\n",
        "    Transcribes an audio file to text using the loaded ASR model.\n",
        "    \"\"\"\n",
        "\n",
        "    waveform, sample_rate = load_audio_and_resample(file_path, target_sample_rate=16000);\n",
        "\n",
        "\n",
        "    input_values = asr_processor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\").input_values;\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = asr_model(input_values).logits;\n",
        "\n",
        "    predicted_ids = torch.argmax(logits, dim=-1);\n",
        "    transcription = asr_processor.batch_decode(predicted_ids)[0];\n",
        "    return transcription;\n",
        "\n",
        "print(\"Updated 'transcribe_audio' to use 'load_audio_and_resample'.\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function 'load_audio_and_resample' defined for general audio processing.\n",
            "Updated 'transcribe_audio' to use 'load_audio_and_resample'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5323e420"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "wav_files_base_path = \"/content/drive/MyDrive/WuHaoAllenCentad/stress_id_wav_filtered\"\n",
        "\n",
        "all_files = os.listdir(wav_files_base_path)\n",
        "\n",
        "wav_files = [f for f in all_files if f.endswith('.wav')]\n",
        "results = []\n",
        "\n",
        "for file_name in wav_files:\n",
        "    full_file_path = os.path.join(wav_files_base_path, file_name)\n",
        "    print(f\" cur file: {file_name}\")\n",
        "\n",
        "    if not os.path.exists(full_file_path):\n",
        "        print(f\"not found {full_file_path}\")\n",
        "        transcribed_text = \"N/A\"\n",
        "        predicted_stress_probability = \"N/A\"\n",
        "    else:\n",
        "        try:\n",
        "            # process_audio_for_stress now returns probability\n",
        "            transcribed_text, predicted_stress_probability = process_audio_for_stress(full_file_path)\n",
        "            print(f\"  Predicted Stress prob: {predicted_stress_probability:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"error {file_name}: {e}\")\n",
        "            transcribed_text = \"N/A\"\n",
        "            predicted_stress_probability = \"N/A\"\n",
        "\n",
        "    results.append({\n",
        "        \"filename\": file_name,\n",
        "        \"transcription\": transcribed_text,\n",
        "        \"stress_probability\": predicted_stress_probability\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nResults DataFrame:\")\n",
        "print(results_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c40fecb",
        "outputId": "2441a393-fc6e-4a67-d485-c90f21d92a31"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "results_df_cleaned = pd.DataFrame(results);\n",
        "results_df_cleaned['subject/task'] = results_df_cleaned['filename'].apply(lambda x: os.path.splitext(x)[0]);\n",
        "\n",
        "results_df_final = results_df_cleaned[['subject/task', 'stress_probability']];\n",
        "\n",
        "output_csv_path = '/content/drive/MyDrive/speechtexttranscriptionpredicted.csv';\n",
        "results_df_final.to_csv(output_csv_path, index=False);\n",
        "\n",
        "print(f\"saved to '{output_csv_path}'.\");\n",
        "print(results_df_final.head());"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results successfully saved to '/content/drive/MyDrive/speechtexttranscriptionpredicted.csv'.\n",
            "First 5 rows of the saved DataFrame:\n",
            "     subject/task  stress_probability\n",
            "0  t6v9_Counting2            0.008007\n",
            "1  t6v9_Counting3            0.005339\n",
            "2     t6v9_Stroop            0.003146\n",
            "3       t6v9_Math            0.004755\n",
            "4  t6v9_Counting1            0.008945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "263aa63f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/WuHaoAllenCentad/stressidtest2.csv');\n",
        "print(\"First 5 rows of validation_df:\");\n",
        "print(validation_df.head());\n",
        "\n",
        "\n",
        "predictions_df = pd.read_csv('/content/drive/MyDrive/speechtexttranscriptionpredicted.csv');\n",
        "print(\"First 5 rows of predictions_df:\");\n",
        "print(predictions_df.head());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e9634d4"
      },
      "source": [
        "#rename columns\n",
        "validation_df = validation_df.rename(columns={'subject/task': 'subject_task'});\n",
        "print(\"validation_df columns after renaming:\");\n",
        "print(validation_df.columns);\n",
        "\n",
        "predictions_df['predicted stressed probability'] = pd.to_numeric(predictions_df['predicted stressed probability'], errors='coerce');\n",
        "print(\"\\npredictions_df info after converting 'predicted stressed probability' to numeric:\");\n",
        "predictions_df.info();\n",
        "\n",
        "print(validation_df.head());\n",
        "print(predictions_df.head());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeca49dd"
      },
      "source": [
        "merged_df = pd.merge(validation_df, predictions_df, on='subject_task', how='inner');\n",
        "\n",
        "print(merged_df.head());"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eedcd33",
        "outputId": "2a6ea8a1-b2d5-4a8d-8955-96e7dcd2f54b"
      },
      "source": [
        "# get labels\n",
        "true_labels = merged_df['binary-stress'];\n",
        "print(true_labels.head());\n",
        "\n",
        "\n",
        "predicted_probabilities = merged_df['predicted stressed probability'];\n",
        "print(predicted_probabilities.head());"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted true_labels. First 5 values:\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: binary-stress, dtype: int64\n",
            "\n",
            "Extracted predicted_probabilities. First 5 values:\n",
            "0    0.010016\n",
            "1    0.012527\n",
            "2    0.004846\n",
            "3    0.002763\n",
            "4    0.001794\n",
            "Name: predicted stressed probability, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "894f36e5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "predicted_labels = (predicted_probabilities >= 0.5).astype(int);\n",
        "\n",
        "print(predicted_labels.head());"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
