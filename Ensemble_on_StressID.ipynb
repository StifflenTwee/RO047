{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkT5pq6ykI0w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive');\n",
        "\n",
        "\n",
        "opensmile_path = \"/content/drive/MyDrive/WuHaoAllenCentad/audiosegmentationopensmilepredictions.csv\";\n",
        "wav2vec_path = \"/content/drive/MyDrive/WuHaoAllenCentad/wav2vec2predictions.csv\";\n",
        "text_path = \"/content/drive/MyDrive/speechtexttranscriptionpredicted.csv\";\n",
        "classic_path=\"/content/drive/MyDrive/logistic_regression_predictions.csv\";\n",
        "\n",
        "\n",
        "try:\n",
        "    df_opensmile = pd.read_csv(opensmile_path);\n",
        "    print(f\"Loaded OpenSmile data from {opensmile_path}\");\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenSmile data: {e}\");\n",
        "    df_opensmile = pd.DataFrame(columns=['subject/task', 'stress_probability']);\n",
        "\n",
        "try:\n",
        "    df_wav2vec = pd.read_csv(wav2vec_path);\n",
        "    print(f\"Loaded Wav2Vec2 data from {wav2vec_path}\");\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Wav2Vec2 data: {e}\");\n",
        "    df_wav2vec = pd.DataFrame(columns=['subject/task', 'stress_probability']);\n",
        "\n",
        "try:\n",
        "    df_text = pd.read_csv(text_path);\n",
        "    print(f\"Loaded Text/BERT data from {text_path}\");\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Text/BERT data: {e}\");\n",
        "    df_text = pd.DataFrame(columns=['subject/task', 'predicted stressed probability']);\n",
        "\n",
        "try:\n",
        "    df_classic = pd.read_csv(classic_path);\n",
        "    print(f\"Loaded Text/BERT data from {classic_path}\");\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Text/BERT data: {e}\");\n",
        "    df_text = pd.DataFrame(columns=['subject/task', 'predicted_stress_probability']);\n",
        "\n",
        "display(df_classic.head());\n",
        "\n",
        "def preprocess_df(df, source_name):\n",
        "\n",
        "    if 'subject_task' in df.columns and 'subject/task' not in df.columns:\n",
        "        df = df.rename(columns={'subject_task': 'subject/task'});\n",
        "    if (('predicted stressed probability' in df.columns) or (\"predicted_stressed_probability\" in df.columns)) and 'stress_probability' not in df.columns:\n",
        "        df = df.rename(columns={'predicted stressed probability': 'stress_probability', \"predicted_stressed_probability\":\"stress_probability\"});\n",
        "\n",
        "\n",
        "    if 'subject/task' not in df.columns or 'stress_probability' not in df.columns:\n",
        "        print(f\"Warning: Required columns missing in {source_name} dataframe. Columns: {df.columns}\");\n",
        "        return pd.DataFrame(columns=['subject/task', f'prob_{source_name}']);\n",
        "\n",
        "\n",
        "    df_agg = df.groupby('subject/task')['stress_probability'].mean().reset_index();\n",
        "\n",
        "\n",
        "    new_col_name = f'prob_{source_name}';\n",
        "    df_agg = df_agg.rename(columns={'stress_probability': new_col_name});\n",
        "\n",
        "    return df_agg;\n",
        "\n",
        "\n",
        "df_opensmile_processed = preprocess_df(df_opensmile, 'opensmile');\n",
        "df_wav2vec_processed = preprocess_df(df_wav2vec, 'wav2vec');\n",
        "df_text_processed = preprocess_df(df_text, 'text');\n",
        "df_classic_processed = preprocess_df(df_classic, 'classic');\n",
        "\n",
        "\n",
        "print(\"\\nOpenSmile Predictions (Processed):\");\n",
        "print(df_opensmile_processed.head());\n",
        "print(\"\\nWav2Vec2 Predictions (Processed):\");\n",
        "print(df_wav2vec_processed.head());\n",
        "print(\"\\nText/BERT Predictions (Processed):\");\n",
        "print(df_text_processed.head());\n",
        "print(\"\\nClassic Predictions (Processed):\");\n",
        "print(df_classic_processed.head());"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "merged_temp = pd.merge(df_opensmile_processed, df_wav2vec_processed, on='subject/task', how='inner');\n",
        "features_df = pd.merge(merged_temp, df_text_processed, on='subject/task', how='inner');\n",
        "\n",
        "features_df = pd.merge(features_df, df_classic_processed, on='subject/task', how='inner');\n",
        "\n",
        "\n",
        "print(f\"Merged Features DataFrame Shape: {features_df.shape}\");\n",
        "print(\"First 5 rows of features_df:\");\n",
        "print(features_df.head());"
      ],
      "metadata": {
        "id": "qGJKeXKrkRLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/WuHaoAllenCentad/stressidtrainbalanced2.csv\";\n",
        "val_path = \"/content/drive/MyDrive/WuHaoAllenCentad/stressidtest2.csv\";\n",
        "\n",
        "\n",
        "df_train_labels = pd.read_csv(train_path);\n",
        "df_val_labels = pd.read_csv(val_path);\n",
        "\n",
        "\n",
        "if 'subject_task' in df_train_labels.columns:\n",
        "    df_train_labels = df_train_labels.rename(columns={'subject_task': 'subject/task'});\n",
        "if 'subject_task' in df_val_labels.columns:\n",
        "    df_val_labels = df_val_labels.rename(columns={'subject_task': 'subject/task'});\n",
        "\n",
        "\n",
        "train_merged = pd.merge(df_train_labels, features_df, on='subject/task', how='inner');\n",
        "val_merged = pd.merge(df_val_labels, features_df, on='subject/task', how='inner');\n",
        "\n",
        "\n",
        "feature_cols = ['prob_opensmile', 'prob_wav2vec', \"prob_text\",\"prob_classic\"];\n",
        "\n",
        "\n",
        "target_col = 'binary-stress';\n",
        "\n",
        "\n",
        "X_train = train_merged[feature_cols];\n",
        "y_train = train_merged[target_col];\n",
        "\n",
        "X_val = val_merged[feature_cols];\n",
        "y_val = val_merged[target_col];\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\");\n",
        "print(f\"Validation set shape: {X_val.shape}\");\n",
        "print(\"First 5 rows of X_train:\");\n",
        "print(X_train.head());\n",
        "print(y_train.head());"
      ],
      "metadata": {
        "id": "rlixqc4mkSvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "weights = {\n",
        "    'prob_classic': 0.6934,\n",
        "    'prob_wav2vec': 0.6358,\n",
        "    'prob_opensmile': 0.656,\n",
        "    'prob_text': 0.4429\n",
        "};\n",
        "\n",
        "\n",
        "total_weight = sum(weights.values());\n",
        "print(f\"Total Weight: {total_weight}\");\n",
        "\n",
        "\n",
        "X_val_ensemble = X_val.copy();\n",
        "\n",
        "X_val_ensemble['prob_ensemble'] = (\n",
        "    X_val['prob_classic'] * weights['prob_classic'] +\n",
        "    X_val['prob_wav2vec'] * weights['prob_wav2vec'] +\n",
        "    X_val['prob_opensmile'] * weights['prob_opensmile']\n",
        "    + X_val['prob_text'] * weights['prob_text']\n",
        "  ) / total_weight;\n",
        "\n",
        "\n",
        "print(\"First 5 rows of ensemble probabilities:\");\n",
        "print(X_val_ensemble[['prob_classic', 'prob_wav2vec', 'prob_opensmile', 'prob_text', 'prob_ensemble']].head());"
      ],
      "metadata": {
        "id": "LqPjK19lkT8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "y_pred_ensemble = (X_val_ensemble['prob_ensemble'] >= 0.5).astype(int);\n",
        "\n",
        "\n",
        "bal_acc_ens = balanced_accuracy_score(y_val, y_pred_ensemble);\n",
        "f1_macro_ens = f1_score(y_val, y_pred_ensemble, average='macro');\n",
        "roc_auc_ens = roc_auc_score(y_val, X_val_ensemble['prob_ensemble']);\n",
        "precision_macro_ens = precision_score(y_val, y_pred_ensemble, average='macro');\n",
        "recall_macro_ens = recall_score(y_val, y_pred_ensemble, average='macro');\n",
        "\n",
        "\n",
        "print(\"Weighted Ensemble Performance:\");\n",
        "print(f\"Balanced Accuracy: {bal_acc_ens:.4f}\");\n",
        "print(f\"F1 (macro):        {f1_macro_ens:.4f}\");\n",
        "print(f\"AUC (ROC-AUC):     {roc_auc_ens:.4f}\");\n",
        "print(f\"Precision (macro): {precision_macro_ens:.4f}\");\n",
        "print(f\"Recall (macro):    {recall_macro_ens:.4f}\");"
      ],
      "metadata": {
        "id": "sub12XR-kVYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "\n",
        "precision_pos = precision_score(y_val, y_pred_ensemble, pos_label=1);\n",
        "recall_pos = recall_score(y_val, y_pred_ensemble, pos_label=1);\n",
        "\n",
        "print(\"Weighted Ensemble Metrics for Positive Class (Stressed):\");\n",
        "print(f\"Precision (Class 1): {precision_pos:.4f}\");\n",
        "print(f\"Recall (Class 1):    {recall_pos:.4f}\");"
      ],
      "metadata": {
        "id": "CnEc80LSkWym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels);\n",
        "\n",
        "\n",
        "report = classification_report(true_labels, predicted_labels, output_dict=True);\n",
        "\n",
        "\n",
        "roc_auc = roc_auc_score(true_labels, predicted_probabilities);\n",
        "\n",
        "print(f\"Overall Accuracy: {accuracy:.4f}\");\n",
        "print(f\"Macro F1-score: {report['macro avg']['f1-score']:.4f}\");\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\");\n",
        "print(f\"Precision (macro avg): {report['macro avg']['precision']:.4f}\");\n",
        "print(f\"Recall (macro avg): {report['macro avg']['recall']:.4f}\");\n",
        "\n",
        "print(\"\\nClassification Report:\");\n",
        "print(classification_report(true_labels, predicted_labels));"
      ],
      "metadata": {
        "id": "XM4t3FcmkYu8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}